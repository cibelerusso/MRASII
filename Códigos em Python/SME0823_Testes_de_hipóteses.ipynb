{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfRvYeKnOJ5bHaPSYJQrVc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cibelerusso/MRASII/blob/main/C%C3%B3digos%20em%20Python/SME0823_Testes_de_hip%C3%B3teses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SME0823 Modelos de Regressão e Aprendizado Supervisionado II\n",
        "\n",
        "# Testes de hipóteses na regressão logística\n",
        "\n",
        "\n",
        "por **Cibele Russo**\n",
        "\n",
        "**ICMC/USP - São Carlos SP**"
      ],
      "metadata": {
        "id": "Yu690ZjEz0KA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "56WCG0B_YSos"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "import statsmodels.api as sm\n",
        "from scipy.special import expit  # sigmoid\n",
        "\n",
        "def simulate_logistic_sample(n, beta0=0.0, beta1=0.0, x_generator=None, rng=None):\n",
        "    \"\"\"\n",
        "    Gera uma amostra (y, X) de um modelo logístico:\n",
        "        logit(p_i) = beta0 + beta1 * x_i\n",
        "        y_i ~ Bernoulli(p_i)\n",
        "\n",
        "    x_generator: função que recebe (n, rng) e retorna vetor x (n,)\n",
        "    \"\"\"\n",
        "    rng = default_rng() if rng is None else rng\n",
        "    if x_generator is None:\n",
        "        # padrão: N(0,1)\n",
        "        x = rng.normal(size=n)\n",
        "    else:\n",
        "        x = x_generator(n, rng)\n",
        "\n",
        "    eta = beta0 + beta1 * x\n",
        "    p = expit(eta)\n",
        "    y = rng.binomial(1, p, size=n)\n",
        "\n",
        "    # Matriz do modelo:\n",
        "    X_full = np.column_stack((np.ones(n), x))  # [1, x]\n",
        "    X_restricted = np.ones((n, 1))            # [1]\n",
        "    return y, X_full, X_restricted, x\n",
        "\n",
        "\n",
        "def fit_logit(y, X):\n",
        "    \"\"\"\n",
        "    Ajusta modelo Logit com statsmodels (máxima verossimilhança).\n",
        "    Retorna o objeto results (LogitResults).\n",
        "    \"\"\"\n",
        "    model = sm.Logit(y, X)\n",
        "    # método por padrão é Newton-Raphson; usar disp=0 pra silenciar\n",
        "    res = model.fit(disp=0)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Estatísticas de teste\n",
        "# ------------------------------------------------------------\n",
        "def lr_test(y, X_full, X_restricted):\n",
        "    \"\"\"\n",
        "    Teste da Razão de Verossimilhança (LR) para H0: restrição que remove a(s) col(s)\n",
        "    de X_full que não estão em X_restricted (aqui: β1=0).\n",
        "    Estatística: 2*(ll_full - ll_restricted) ~ qui2_{df}, df = p_full - p_restricted\n",
        "    \"\"\"\n",
        "    res_full = fit_logit(y, X_full)\n",
        "    res_rest = fit_logit(y, X_restricted)\n",
        "    llf_full = res_full.llf\n",
        "    llf_rest = res_rest.llf\n",
        "    stat = 2.0 * (llf_full - llf_rest)\n",
        "    df = X_full.shape[1] - X_restricted.shape[1]\n",
        "    return stat, df\n",
        "\n",
        "\n",
        "def wald_test(y, X_full, param_index=1):\n",
        "    \"\"\"\n",
        "    Teste de Wald para H0: beta[param_index] = 0 no modelo completo.\n",
        "    Estatística: (beta_hat / SE)^2 ~ qui2_1.\n",
        "    Por padrão, param_index=1 testa a covariável x (assumindo [intercepto, x]).\n",
        "    \"\"\"\n",
        "    res_full = fit_logit(y, X_full)\n",
        "    beta_hat = res_full.params[param_index]\n",
        "    se = np.sqrt(res_full.cov_params()[param_index, param_index])\n",
        "    z = beta_hat / se\n",
        "    stat = z**2\n",
        "    df = 1\n",
        "    return stat, df\n",
        "\n",
        "\n",
        "def score_test_intercept_plus_x(y, X_restricted, x):\n",
        "    \"\"\"\n",
        "    Teste de Score (LM) para H0: beta1 = 0 em modelo com intercepto + 1 covariável x.\n",
        "    Implementação clássica do score sob H0:\n",
        "        U = sum x_i * (y_i - mu0_i)\n",
        "        I = sum x_i^2 * mu0_i*(1-mu0_i)   (informação para beta1 sob H0)\n",
        "    Estatística: LM = U^2 / I ~ qui2_1.\n",
        "    \"\"\"\n",
        "    # Ajusta modelo restrito: apenas intercepto\n",
        "    res_rest = fit_logit(y, X_restricted)\n",
        "    eta0 = (X_restricted @ res_rest.params)  # vetor n x 1 de preditores lineares sob H0\n",
        "    mu0 = expit(eta0)\n",
        "\n",
        "    resid = y - mu0\n",
        "    U = np.sum(x * resid)\n",
        "    I = np.sum((x**2) * mu0 * (1 - mu0))\n",
        "    # Evitar divisão por zero:\n",
        "    if I <= 1e-12:\n",
        "        return np.nan, 1\n",
        "    LM = (U**2) / I\n",
        "    df = 1\n",
        "    return LM, df\n",
        "\n"
      ],
      "metadata": {
        "id": "SSvD7cNx0N8B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ------------------------------------------------------------\n",
        "# Simulação (tamanho e poder)\n",
        "# ------------------------------------------------------------\n",
        "def simulate_rejection_rates(\n",
        "    n=200,\n",
        "    beta0=0.0,\n",
        "    beta1=0.0,\n",
        "    reps=1000,\n",
        "    alpha=0.05,\n",
        "    x_generator=None,\n",
        "    rng=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Retorna as taxas de rejeição empíricas (LR, Wald, Score) ao nível alpha,\n",
        "    para amostras geradas de um logit com parâmetros (beta0, beta1).\n",
        "    \"\"\"\n",
        "    rng = default_rng() if rng is None else rng\n",
        "    from scipy.stats import chi2\n",
        "\n",
        "    lr_reject = 0\n",
        "    wald_reject = 0\n",
        "    score_reject = 0\n",
        "    valid_score = 0\n",
        "\n",
        "    chi2_crit_1 = chi2.ppf(1 - alpha, df=1)\n",
        "\n",
        "    for _ in range(reps):\n",
        "        y, X_full, X_rest, x = simulate_logistic_sample(\n",
        "            n=n, beta0=beta0, beta1=beta1, x_generator=x_generator, rng=rng\n",
        "        )\n",
        "\n",
        "        # LR\n",
        "        try:\n",
        "            lr_stat, lr_df = lr_test(y, X_full, X_rest)\n",
        "            if lr_stat >= chi2.ppf(1 - alpha, df=lr_df):\n",
        "                lr_reject += 1\n",
        "        except Exception:\n",
        "            # pode falhar se separação/quase-separação ocorrer; ignoramos esta replicação\n",
        "            pass\n",
        "\n",
        "        # Wald\n",
        "        try:\n",
        "            wald_stat, _ = wald_test(y, X_full, param_index=1)\n",
        "            if wald_stat >= chi2_crit_1:\n",
        "                wald_reject += 1\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # Score (LM) - versão intercepto + 1 x\n",
        "        try:\n",
        "            score_stat, _ = score_test_intercept_plus_x(y, X_rest, x)\n",
        "            if np.isfinite(score_stat):\n",
        "                valid_score += 1\n",
        "                if score_stat >= chi2_crit_1:\n",
        "                    score_reject += 1\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    results = {\n",
        "        \"alpha\": alpha,\n",
        "        \"n\": n,\n",
        "        \"reps\": reps,\n",
        "        \"beta0\": beta0,\n",
        "        \"beta1\": beta1,\n",
        "        \"size_or_power\": {\n",
        "            \"LR\": lr_reject / reps,\n",
        "            \"Wald\": wald_reject / reps,\n",
        "            \"Score\": (score_reject / valid_score) if valid_score > 0 else np.nan,\n",
        "            \"Score_valid_fraction\": valid_score / reps,\n",
        "        },\n",
        "    }\n",
        "    return results"
      ],
      "metadata": {
        "id": "Pk1zEcXq1kUA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Exemplo de uso\n",
        "# ------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    rng = default_rng(2025)\n",
        "\n",
        "    # Gerador de X: Normal(0,1)\n",
        "    def xgen(n, rng):\n",
        "        return rng.normal(size=n)\n",
        "\n",
        "    # 1) Tamanho (nível empírico) sob H0: beta1 = 0\n",
        "    res_size = simulate_rejection_rates(\n",
        "        n=300, beta0=0.0, beta1=0.0, reps=2000, alpha=0.05, x_generator=xgen, rng=rng\n",
        "    )\n",
        "    print(\"=== Tamanho (H0: beta1=0) ===\")\n",
        "    print(res_size)\n",
        "\n",
        "    # 2) Poder sob H1: beta1 != 0 (ex.: efeitos moderados)\n",
        "    for b1 in [0.2, 0.4, 0.6]:\n",
        "        res_power = simulate_rejection_rates(\n",
        "            n=300, beta0=0.0, beta1=b1, reps=2000, alpha=0.05, x_generator=xgen, rng=rng\n",
        "        )\n",
        "        print(f\"=== Poder (H1: beta1={b1}) ===\")\n",
        "        print(res_power)"
      ],
      "metadata": {
        "id": "Koo__J-xYTzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125b7023-0b07-4236-d984-e2d1f533b885"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Tamanho (H0: beta1=0) ===\n",
            "{'alpha': 0.05, 'n': 300, 'reps': 2000, 'beta0': 0.0, 'beta1': 0.0, 'size_or_power': {'LR': 0.0495, 'Wald': 0.0475, 'Score': 0.048, 'Score_valid_fraction': 1.0}}\n",
            "=== Poder (H1: beta1=0.2) ===\n",
            "{'alpha': 0.05, 'n': 300, 'reps': 2000, 'beta0': 0.0, 'beta1': 0.2, 'size_or_power': {'LR': 0.409, 'Wald': 0.4005, 'Score': 0.405, 'Score_valid_fraction': 1.0}}\n",
            "=== Poder (H1: beta1=0.4) ===\n",
            "{'alpha': 0.05, 'n': 300, 'reps': 2000, 'beta0': 0.0, 'beta1': 0.4, 'size_or_power': {'LR': 0.922, 'Wald': 0.9205, 'Score': 0.9205, 'Score_valid_fraction': 1.0}}\n",
            "=== Poder (H1: beta1=0.6) ===\n",
            "{'alpha': 0.05, 'n': 300, 'reps': 2000, 'beta0': 0.0, 'beta1': 0.6, 'size_or_power': {'LR': 0.9995, 'Wald': 0.9995, 'Score': 0.9995, 'Score_valid_fraction': 1.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y52gG54Gtmjl"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}